
Name: Sagar Giradkar
RollNo: 3051
Ass: WordCount Using java And Hadoop Integration


////////////////////////Driver.java/////////////////////////////

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class Driver {

	public static void main(String args[]) throws Exception{
		Configuration c =new Configuration();
		@SuppressWarnings("deprecation")
		Job job=new Job(c,"wordcount");
		job.setJarByClass(Driver.class);
		job.setMapperClass(MapForWordCount.class);
		job.setReducerClass(ReduceForWordCount.class);
		
		job.setOutputKeyClass(Text.class);
		job.setOutputValueClass(IntWritable.class);
		
		FileInputFormat.addInputPath(job, new Path(args[0]));
		
		FileOutputFormat.setOutputPath(job, new Path(args[1]));
		
		System.exit(job.waitForCompletion(true)?0:1);
		
	}
}

//////////////////////////Mapper.java///////////////////////////////////////

import java.io.IOException;


import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class MapForWordCount extends Mapper<LongWritable, Text, Text, IntWritable>{
		public void map(LongWritable offset, Text key, Context con) throws IOException, InterruptedException
		{
		String line = key.toString();
		String words[]=line.split(" ");
			for(String word: words )
			{
			      Text outputKey = new Text(word);
			      IntWritable outputValue = new IntWritable(1);
			      con.write(outputKey, outputValue);
			}
		}
	}
	
///////////////////////////Reducer.java///////////////////////////////////

import java.io.IOException;


import org.apache.hadoop.io.IntWritable;

import org.apache.hadoop.io.Text;

import org.apache.hadoop.mapreduce.Reducer;

public class ReduceForWordCount extends Reducer<Text, IntWritable, Text, IntWritable>
	{
		public void reduce(Text word, Iterable<IntWritable> values, Context con) throws IOException, InterruptedException
		{
			int sum = 0;
			for(IntWritable value : values)
			{
				sum += value.get();
			}
			con.write(word, new IntWritable(sum));
		}
	}
	
	
//////////////////////////////OUPUT OF WORDCOUNT////////////////////////////////////////////

hduser@student-ThinkCentre-M700:~$ hadoop jar MaxLoginTime.jar MaxLoginTime 
/mydata/short.txt /mydata/output799
JAR does not exist or is not a normal file: /home/hduser/MaxLoginTime.jar
hduser@student-ThinkCentre-M700:~$ hadoop jar /home/hduser/Downloads/atharva.jar Driver 
/mydata/file.txt /mydata/output007
2024-04-20 16:52:04,277 WARN util.NativeCodeLoader: Unable to load native-hadoop library 
for your platform... using builtin-java classes where applicable
2024-04-20 16:52:05,286 INFO impl.MetricsConfig: Loaded properties from hadoopmetrics2.properties
2024-04-20 16:52:05,367 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 
10 second(s).
2024-04-20 16:52:05,367 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2024-04-20 16:52:05,526 WARN mapreduce.JobResourceUploader: Hadoop command-line 
option parsing not performed. Implement the Tool interface and execute your application with 
ToolRunner to remedy this.
2024-04-20 16:52:05,618 INFO input.FileInputFormat: Total input files to process : 1
2024-04-20 16:52:05,726 INFO mapreduce.JobSubmitter: number of splits:1
2024-04-20 16:52:05,929 INFO mapreduce.JobSubmitter: Submitting tokens for job: 
job_local968005527_0001
2024-04-20 16:52:05,929 INFO mapreduce.JobSubmitter: Executing with tokens: []
2024-04-20 16:52:06,068 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
2024-04-20 16:52:06,068 INFO mapreduce.Job: Running job: job_local968005527_0001
2024-04-20 16:52:06,069 INFO mapred.LocalJobRunner: OutputCommitter set in config null
2024-04-20 16:52:06,082 INFO output.FileOutputCommitter: File Output Committer Algorithm
version is 2
2024-04-20 16:52:06,082 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup 
_temporary folders under output directory:false, ignore cleanup failures: false
2024-04-20 16:52:06,083 INFO mapred.LocalJobRunner: OutputCommitter is 
org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2024-04-20 16:52:06,134 INFO mapred.LocalJobRunner: Waiting for map tasks
2024-04-20 16:52:06,135 INFO mapred.LocalJobRunner: Starting task: 
attempt_local968005527_0001_m_000000_0
2024-04-20 16:52:06,159 INFO output.FileOutputCommitter: File Output Committer Algorithm 
version is 2
2024-04-20 16:52:06,159 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup 
_temporary folders under output directory:false, ignore cleanup failures: false
2024-04-20 16:52:06,180 INFO mapred.Task: Using ResourceCalculatorProcessTree : [ ]
2024-04-20 16:52:06,182 INFO mapred.MapTask: Processing split: 
hdfs://localhost:9000/mydata/file.txt:0+300
2024-04-20 16:52:06,662 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
2024-04-20 16:52:06,662 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
2024-04-20 16:52:06,662 INFO mapred.MapTask: soft limit at 83886080
2024-04-20 16:52:06,662 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
2024-04-20 16:52:06,662 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
2024-04-20 16:52:06,671 INFO mapred.MapTask: Map output collector class = 
org.apache.hadoop.mapred.MapTask$MapOutputBuffer
2024-04-20 16:52:07,043 INFO mapred.LocalJobRunner:
2024-04-20 16:52:07,045 INFO mapred.MapTask: Starting flush of map output
2024-04-20 16:52:07,045 INFO mapred.MapTask: Spilling map output
2024-04-20 16:52:07,045 INFO mapred.MapTask: bufstart = 0; bufend = 492; bufvoid = 
104857600
2024-04-20 16:52:07,045 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 
26214208(104856832); length = 189/6553600
2024-04-20 16:52:07,079 INFO mapreduce.Job: Job job_local968005527_0001 running in uber 
mode : false
2024-04-20 16:52:07,079 INFO mapreduce.Job: map 0% reduce 0%
2024-04-20 16:52:07,257 INFO mapred.MapTask: Finished spill 0
2024-04-20 16:52:07,288 INFO mapred.Task: 
Task:attempt_local968005527_0001_m_000000_0 is done. And is in the process of committing
2024-04-20 16:52:07,295 INFO mapred.LocalJobRunner: map
2024-04-20 16:52:07,295 INFO mapred.Task: Task 
'attempt_local968005527_0001_m_000000_0' done.
2024-04-20 16:52:07,304 INFO mapred.Task: Final Counters for 
attempt_local968005527_0001_m_000000_0: Counters: 23
File System Counters
FILE: Number of bytes read=3990
FILE: Number of bytes written=639881
FILE: Number of read operations=0
FILE: Number of large read operations=0
FILE: Number of write operations=0
HDFS: Number of bytes read=300
HDFS: Number of bytes written=0
HDFS: Number of read operations=5
HDFS: Number of large read operations=0
HDFS: Number of write operations=1
HDFS: Number of bytes read erasure-coded=0
Map-Reduce Framework
Map input records=1
Map output records=48
Map output bytes=492
Map output materialized bytes=594
Input split bytes=102
Combine input records=0
Spilled Records=48
Failed Shuffles=0
Merged Map outputs=0
GC time elapsed (ms)=7
Total committed heap usage (bytes)=374865920
File Input Format Counters
Bytes Read=300
2024-04-20 16:52:07,304 INFO mapred.LocalJobRunner: Finishing task: 
attempt_local968005527_0001_m_000000_0
2024-04-20 16:52:07,305 INFO mapred.LocalJobRunner: map task executor complete.
2024-04-20 16:52:07,307 INFO mapred.LocalJobRunner: Waiting for reduce tasks
2024-04-20 16:52:07,307 INFO mapred.LocalJobRunner: Starting task: 
attempt_local968005527_0001_r_000000_0
2024-04-20 16:52:07,313 INFO output.FileOutputCommitter: File Output Committer Algorithm 
version is 2
2024-04-20 16:52:07,313 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup 
_temporary folders under output directory:false, ignore cleanup failures: false
2024-04-20 16:52:07,313 INFO mapred.Task: Using ResourceCalculatorProcessTree : [ ]
2024-04-20 16:52:07,316 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: 
org.apache.hadoop.mapreduce.task.reduce.Shuffle@21c4409e
2024-04-20 16:52:07,319 WARN impl.MetricsSystemImpl: JobTracker metrics system already 
initialized!
2024-04-20 16:52:07,334 INFO reduce.MergeManagerImpl: MergerManager: 
memoryLimit=1280101504, maxSingleShuffleLimit=320025376, mergeThreshold=844867008, 
ioSortFactor=10, memToMemMergeOutputsThreshold=10
2024-04-20 16:52:07,336 INFO reduce.EventFetcher: 
attempt_local968005527_0001_r_000000_0 Thread started: EventFetcher for fetching Map 
Completion Events
2024-04-20 16:52:07,381 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of 
map attempt_local968005527_0001_m_000000_0 decomp: 590 len: 594 to MEMORY
2024-04-20 16:52:07,383 INFO reduce.InMemoryMapOutput: Read 590 bytes from map-output 
for attempt_local968005527_0001_m_000000_0
2024-04-20 16:52:07,384 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output 
of size: 590, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->590
2024-04-20 16:52:07,385 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
2024-04-20 16:52:07,386 INFO mapred.LocalJobRunner: 1 / 1 copied.
2024-04-20 16:52:07,386 INFO reduce.MergeManagerImpl: finalMerge called with 1 inmemory map-outputs and 0 on-disk map-outputs
2024-04-20 16:52:07,393 INFO mapred.Merger: Merging 1 sorted segments
2024-04-20 16:52:07,393 INFO mapred.Merger: Down to the last merge-pass, with 1 segments 
left of total size: 586 bytes
2024-04-20 16:52:07,397 INFO reduce.MergeManagerImpl: Merged 1 segments, 590 bytes to 
disk to satisfy reduce memory limit
2024-04-20 16:52:07,397 INFO reduce.MergeManagerImpl: Merging 1 files, 594 bytes from 
disk
2024-04-20 16:52:07,398 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from 
memory into reduce
2024-04-20 16:52:07,398 INFO mapred.Merger: Merging 1 sorted segments
2024-04-20 16:52:07,398 INFO mapred.Merger: Down to the last merge-pass, with 1 segments 
left of total size: 586 bytes
2024-04-20 16:52:07,399 INFO mapred.LocalJobRunner: 1 / 1 copied.
2024-04-20 16:52:07,492 INFO Configuration.deprecation: mapred.skip.on is deprecated. 
Instead, use mapreduce.job.skiprecords
2024-04-20 16:52:07,607 INFO mapred.Task: Task:attempt_local968005527_0001_r_000000_0 
is done. And is in the process of committing
2024-04-20 16:52:07,610 INFO mapred.LocalJobRunner: 1 / 1 copied.
2024-04-20 16:52:07,610 INFO mapred.Task: Task attempt_local968005527_0001_r_000000_0 
is allowed to commit now
2024-04-20 16:52:07,631 INFO output.FileOutputCommitter: Saved output of task 
'attempt_local968005527_0001_r_000000_0' to hdfs://localhost:9000/mydata/output007
2024-04-20 16:52:07,631 INFO mapred.LocalJobRunner: reduce > reduce
2024-04-20 16:52:07,631 INFO mapred.Task: Task 
'attempt_local968005527_0001_r_000000_0' done.
2024-04-20 16:52:07,632 INFO mapred.Task: Final Counters for 
attempt_local968005527_0001_r_000000_0: Counters: 30
File System Counters
FILE: Number of bytes read=5210
FILE: Number of bytes written=640475
FILE: Number of read operations=0
FILE: Number of large read operations=0
FILE: Number of write operations=0
HDFS: Number of bytes read=300
HDFS: Number of bytes written=355
HDFS: Number of read operations=10
HDFS: Number of large read operations=0
HDFS: Number of write operations=3
HDFS: Number of bytes read erasure-coded=0
Map-Reduce Framework
Combine input records=0
Combine output records=0
Reduce input groups=41
Reduce shuffle bytes=594
Reduce input records=48
Reduce output records=41
Spilled Records=48
Shuffled Maps =1
Failed Shuffles=0
Merged Map outputs=1
GC time elapsed (ms)=0
Total committed heap usage (bytes)=374865920
Shuffle Errors
BAD_ID=0
CONNECTION=0
IO_ERROR=0
WRONG_LENGTH=0
WRONG_MAP=0
WRONG_REDUCE=0
File Output Format Counters
Bytes Written=355
2024-04-20 16:52:07,632 INFO mapred.LocalJobRunner: Finishing task: 
attempt_local968005527_0001_r_000000_0
2024-04-20 16:52:07,632 INFO mapred.LocalJobRunner: reduce task executor complete.
2024-04-20 16:52:08,082 INFO mapreduce.Job: map 100% reduce 100%
2024-04-20 16:52:08,082 INFO mapreduce.Job: Job job_local968005527_0001 completed 
successfully
2024-04-20 16:52:08,098 INFO mapreduce.Job: Counters: 36
File System Counters
FILE: Number of bytes read=9200
FILE: Number of bytes written=1280356
FILE: Number of read operations=0
FILE: Number of large read operations=0
FILE: Number of write operations=0
HDFS: Number of bytes read=600
HDFS: Number of bytes written=355
HDFS: Number of read operations=15
HDFS: Number of large read operations=0
HDFS: Number of write operations=4
HDFS: Number of bytes read erasure-coded=0
Map-Reduce Framework
Map input records=1
Map output records=48
Map output bytes=492
Map output materialized bytes=594
Input split bytes=102
Combine input records=0
Combine output records=0
Reduce input groups=41
Reduce shuffle bytes=594
Reduce input records=48
Reduce output records=41
Spilled Records=96
Shuffled Maps =1
Failed Shuffles=0
Merged Map outputs=1
GC time elapsed (ms)=7
Total committed heap usage (bytes)=749731840
Shuffle Errors
BAD_ID=0
CONNECTION=0
IO_ERROR=0
WRONG_LENGTH=0
WRONG_MAP=0
WRONG_REDUCE=0
File Input Format Counters
Bytes Read=300
File Output Format Counters
Bytes Written=355
hduser@student-ThinkCentre-M700:~$ ^C
hduser@student-ThinkCentre-M700:~$ hdfs dfs -cat /mydata/output799/*
2024-04-20 16:52:37,463 WARN util.NativeCodeLoader: Unable to load native-hadoop library 
for your platform... using builtin-java classes where applicable
10.82.30.199 63
hduser@student-ThinkCentre-M700:~$ hdfs dfs -cat /mydata/output007/*
2024-04-20 16:52:46,539 WARN util.NativeCodeLoader: Unable to load native-hadoop library 
for your platform... using builtin-java classes where applicable
A 1
DataFrame, 1
Excel 1
In 1
It 1
Microsoft 1
Pandas 1
Pivot 1
a 1
as 1
average, 1
component 1
data 1
dataset. 1
elements. 1
in 1
include 1
is 1
large 1
linked 1
may 1
mode, 1
of 1
or 1
originally 1
other 1
pivot 1
processing. 1
quantitative 1
report 1
statistical 1
such 1
summarizes 1
summation, 1
table 1
tables 1
tables, 1
that 1
the 1
were 1
with 1
hduser@student-ThinkCentre-M700:~$